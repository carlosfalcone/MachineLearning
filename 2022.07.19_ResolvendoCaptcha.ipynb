{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fece4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4f0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e724aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f76f3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031272cc",
   "metadata": {},
   "source": [
    "## Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68ddea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista dos nomes de cada amostra\n",
    "nomes_amostras=os.listdir('C:/Users/Falcone/Documents/0_MachineLearning/2022.07.08_Environm_OpenCV/2022.07.19_ResolvendoCaptcha/samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956db653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'226md.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nomes_amostras\n",
    "nomes_amostras[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9609e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abertura de cada arquivo (amostra) de imagem\n",
    "imagens=[]\n",
    "for i in nomes_amostras:\n",
    "    endereco='C:/Users/Falcone/Documents/0_MachineLearning/2022.07.08_Environm_OpenCV/2022.07.19_ResolvendoCaptcha/samples/'+i\n",
    "    img=cv2.imread(endereco)\n",
    "    imagens.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0911dd1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        ...,\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251]],\n",
       "\n",
       "       [[192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        ...,\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251]],\n",
       "\n",
       "       [[192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        [192, 192, 192],\n",
       "        ...,\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251],\n",
       "        [251, 251, 251]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]],\n",
       "\n",
       "       [[195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]],\n",
       "\n",
       "       [[195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        [195, 195, 195],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35f488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formato da imagem\n",
    "imagens[0].shape #50 pixels na vertical(linhas) e 200 pixels na horizontal(colunas) e 3 canais de cores BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91120aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualização da imagem\n",
    "cv2.imshow('Imagem',imagens[0])\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ee944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo de BGR para escala de cinza\n",
    "imagens_cinza=[]\n",
    "for image in imagens:\n",
    "    img_cinza=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    imagens_cinza.append(img_cinza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2ffe28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização da imagem cinza\n",
    "cv2.imshow('Imagem Cinza',imagens_cinza[0])\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c30e309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formato da imagem - conferindo se a imagem foi convertida para escala cinza (sem canais de cores)\n",
    "imagens_cinza[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b623cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificaçao da quantidade das imagens\n",
    "len(imagens_cinza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7211fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaçao de cada caracter de uma imagem\n",
    "cv2.imshow('Imagem Cinza recortada',imagens_cinza[0][12:50,30:50]) #valores dos pixels na vertical(y/linhas) e na horizontal(x/colunas)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5601cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaçao de cada caracter de uma imagem\n",
    "cv2.imshow('Imagem Cinza recortada',imagens_cinza[0][12:50,70:90]) #valores dos pixels na vertical(y/linhas) e na horizontal(x/colunas)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abe828c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separaçao de cada caracter em uma imagem distinta - Novo dataset \"img_caracteres\"\n",
    "xini,yini,largura,altura=30,12,20,38 #pontos inicias dos pixels, largura e altura de pixels\n",
    "img_caracteres=np.zeros((len(nomes_amostras)*5,altura,largura)) #criaçao de matriz de zeros como ponto de partida (qtd amostras (5 caracteres dentro de cada sample), qtd pixels vertical, qtd pixels horizontal)\n",
    "for i in range(len(imagens_cinza)): # seleciona um sample\n",
    "    px=xini\n",
    "    for j in range(5): # seleciona cada caractere dentro de um sample\n",
    "        img_caracteres[i*5+j]=imagens_cinza[i][yini:yini+altura, px:px+largura]\n",
    "        cv2.imwrite('C:/Users/Falcone/Documents/0_MachineLearning/2022.07.08_Environm_OpenCV/2022.07.19_ResolvendoCaptcha/TesteCaracter/CaracterTeste.jpg',img_caracteres[i*5+j])\n",
    "        px+=largura # pula para o proximo caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e09b69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizaçao da imagem salva no computador\n",
    "#Posteriormente irei trabalhar com essas imagens de resoluçao mais alta para ver se a acuracia do modelo aumenta!\n",
    "img_carac_teste=cv2.imread('C:/Users/Falcone/Documents/0_MachineLearning/2022.07.08_Environm_OpenCV/2022.07.19_ResolvendoCaptcha/TesteCaracter/CaracterTeste.jpg')\n",
    "cv2.imshow('Imagem caracter Salva',img_carac_teste)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc98197",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_caracteres[0].shape #formato/qtd de pixels de cada imagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_caracteres) #Numero de amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaçao do valor maximo dos dados\n",
    "img_caracteres.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização da imagem de cada caractere recortado\n",
    "#Por que a resoluçao da imagem ficou ruim??\n",
    "#Será que um dos motivos para a rede neural ter ficado com um valor baixo de acuracia foi devido a essa baixa resolução da imagem?\n",
    "cv2.imshow('Imagem caracter',img_caracteres[2])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe05956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparação das imagens para a rede neural (normalizaçao e mudança de shape)\n",
    "img_caracteres2=np.zeros((img_caracteres.shape[0],img_caracteres.shape[1],img_caracteres.shape[2],1)) #Matriz de zeros como ponto de partida para adiçao do canal de cor cinza\n",
    "for i in range(img_caracteres.shape[0]):\n",
    "    #norm=img_caracteres/255 #Normalizaçao dos dados\n",
    "    img=np.reshape(img_caracteres[i]/255,(img_caracteres.shape[1],img_caracteres.shape[2],1)) #Adiçao do canal de cor: cinza\n",
    "    img_caracteres2[i]=img #Adição de cada uma das imagens no novo dataset img_caracteres2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaçao do valor maximo dos dados para certificar que foram normalizados\n",
    "img_caracteres2.max() \n",
    "#O Natanael fez algo errado no codigo, pois os dados nao foram normalizados\n",
    "# eliminei o codigo \"norm=...\"\n",
    "#inclui a divisao por 255 no codigo  \"img=np.reshape(img_caracteres[i]/255,...\"\n",
    "#Agora sim ficou normalizado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53738fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Certificaçao do novo formato dos dados\n",
    "img_caracteres2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a variavel target\n",
    "y_atual=nomes_amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste de remoção do \".png\" no final do nome \n",
    "y_atual[0][0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remoção do \".png\" no final dos nomes\n",
    "for i in range(len(y_atual)):\n",
    "    y_atual[i]=y_atual[i][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaçao da remoçao do final .png\n",
    "y_atual[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9976b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db239909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separaçao de cada caracter do nome, para alinhamento com os dados de entrada\n",
    "y=[None]*img_caracteres2.shape[0] #Definiçao da dimensao da lista\n",
    "for i in range(len(y_atual)):\n",
    "    for j in range(5):\n",
    "        y[i*5+j]=y_atual[i][j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaçao\n",
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38362d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaçao\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc30f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding da variavel y\n",
    "#Agrupamento de todas as classes possiveis em uma unica string\n",
    "import string\n",
    "simbolos=string.ascii_lowercase + '0123456789'\n",
    "simbolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolos.find('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final=np.zeros((len(y),36)) #Definiçao da dimensao final (5350 amostras, 36 classes)\n",
    "for i in range(len(y)):\n",
    "#for i in range(3):\n",
    "    caractere=y[i] #Pega o caractere\n",
    "    #print(y[i])\n",
    "    loc_caractere=simbolos.find(caractere) #Encontra a localizaçao correspondente desse caractere\n",
    "    #print(loc_caractere)\n",
    "    y_final[i,loc_caractere]=1 #Atruibui qual a classe de cada elemento contido em y[i]\n",
    "    #print(y_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03364d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee87bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e53c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02226a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtreino,xteste,ytreino,yteste=train_test_split(img_caracteres2,y_final,test_size=0.2,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension #Adiçao do canal de cor (escala de cinza)\n",
    "xtreino = xtreino.astype(\"float32\")\n",
    "xteste = xteste.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtreino.shape)\n",
    "print(ytreino.shape)\n",
    "print(xteste.shape)\n",
    "print(yteste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ad4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c380974a",
   "metadata": {},
   "source": [
    "## Contruçao e execuçao da rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9336300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para definição da camada de convoluçao\n",
    "def conv2d(entrada,w,b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(entrada,w,strides=[1,1,1,1],padding='VALID'),b)) #padding=VALID quer dizer que o padding nao sera utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para definição da camada de Maxpool\n",
    "def maxpool(entrada1,k):\n",
    "    return tf.nn.max_pool(entrada1, ksize=[1,k,k,1],strides=[1,k,k,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializaçao dos pesos\n",
    "w1=tf.Variable(tf.random.normal([3,3,1,32],0,0.05,tf.float32)) #camada CNN interna1 filtro(kernel) 3x3, conectada a 1 imagem para varrer, 32 feature maps de saida, media zero e desvio padrao 0.05\n",
    "w2=tf.Variable(tf.random.normal([3,3,32,64],0,0.05,tf.float32)) #camada CNN interna2 filtro 3x3, conectada 32 pooling layers anteriores, e 64 fetaure maps de saida\n",
    "w3=tf.Variable(tf.random.normal([16*7*64,80],0,0.05,tf.float32)) #64 featuremaps 16x7 dispostos em apenas 1 coluna (flatten), Camada Densa de 80 neuronios \n",
    "wout=tf.Variable(tf.random.normal([80,36],0,0.05,tf.float32)) #Camada densa de 80 neuronios, Camada densa de saida de 36 neuronios (36 classes)\n",
    "#Calculo para determinaçao dos parametros\n",
    "#imagem de entrada: 38x20 pixels\n",
    "#Primeira camada CNN, com filtro 3x3, irá reduzir a imagem para tamanho 36x18 pixels\n",
    "#Primeiro Pooling, tamanho 2x2 e stride(passo)2, irá reduzir o feature map anterior para 18x9 pixels\n",
    "#Segunda camada CNN, tamanho 3x3, irá reduzir o Pooling anterior para tamanho 16x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28074d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializaçao dos bias\n",
    "b1=tf.Variable(tf.zeros([32]))\n",
    "b2=tf.Variable(tf.zeros([64]))\n",
    "b3=tf.Variable(tf.zeros([80]))\n",
    "bout=tf.Variable(tf.zeros([36]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de saida (resultado do modelo)\n",
    "@tf.function\n",
    "def saida(entrada,w1,w2,w3,wout,b1,b2,b3,bout):\n",
    "    #Camada CNN1\n",
    "    conv1=conv2d(entrada,w1,b1) \n",
    "    pool1=maxpool(conv1,k=2)\n",
    "    #Camada CNN2\n",
    "    conv2=conv2d(pool1,w2,b2)\n",
    "    ##pool2=maxpool(conv2,k=2)\n",
    "    #Camada densa oculta\n",
    "    convcoluna=tf.reshape(conv2, shape=[-1,w3.get_shape().as_list()[0]])\n",
    "    densa1=tf.nn.relu(tf.add(tf.matmul(convcoluna, w3),b3))\n",
    "    ##dropoutdensa=tf.nn.dropout(densa1,0.2)\n",
    "    #Camda densa de saída\n",
    "    saida=tf.add(tf.matmul(densa1,wout),bout)\n",
    "    #return conv2\n",
    "    return saida\n",
    "saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de custo\n",
    "@tf.function\n",
    "def cost(saida,gabtreino):\n",
    "    error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=saida, labels=gabtreino))\n",
    "    return error\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1282e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otimizador\n",
    "optimizer = tf.optimizers.Adam() #O otimizador Adam minimizou a oscilaçao da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variaveis a serem treinadas\n",
    "trainable_vars = [w1,w2,w3,wout,b1,b2,b3,bout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "x=[] #Lista para armazenar a quantidade de batches\n",
    "y=0 #Complemento para Lista para armazenar a quantidade de batches\n",
    "epochs = 10 #DADO DE ENTRADA #(or however many iterations you want it to run)\n",
    "listacustotreino=[]\n",
    "listaacurtreino=[]\n",
    "listaacurteste=[]\n",
    "tempoinicial=time.time()\n",
    "\n",
    "for _ in range(epochs): #loop for das épocas\n",
    "    y=y+1\n",
    "    x.append(y)\n",
    "    #print('epoca:',y)\n",
    "    tamanhobatch=428 #DADO DE ENTRADA\n",
    "    deltabatch=tamanhobatch #Mesmo valor que tamanhobatch, porem este numero nao varia dentro do loop for\n",
    "    batches=4280/tamanhobatch #DADO DE ENTRADA #Tamanho das amostras de treino/tamanhobatch\n",
    "    batchesint=int(batches) #Quantidade de batches no formato integer (numero inteiro)\n",
    "    #print('numero total de batches:',batchesint)\n",
    "    m=0\n",
    "    #Utilizar batches para fazer o calculo de custo e atualizaçao dos pesos e bias\n",
    "    for n in range (batchesint): #Loop for de cada batch de forma a cobrir todos os dados\n",
    "        #print('batch number:',n)\n",
    "        listabatchesxtreino=[]\n",
    "        listabatchesytreino=[]\n",
    "        paramif=0\n",
    "        for l in range (m,tamanhobatch): #Loop for das linhas dentro de um batch\n",
    "            #print('Qtd de amostras:',l)\n",
    "            listabatchesxtreino.append(xtreino[l]) #carrega trechos de amostras do banco de dados\n",
    "            listabatchesytreino.append(ytreino[l]) #carrega trechos de amostras do banco de dados\n",
    "            m=m+1\n",
    "            paramif=paramif+1\n",
    "            listabatchesxtreino1=np.array(listabatchesxtreino)\n",
    "            listabatchesytreino1=np.array(listabatchesytreino)\n",
    "            if paramif+1 > deltabatch:\n",
    "                #print('listabatchesxtreino1',listabatchesxtreino1.shape)\n",
    "                with tf.GradientTape() as tp:\n",
    "                #your loss/cost function must always be contained within the gradient tape instantiation\n",
    "                    saidatreino = saida(listabatchesxtreino1,w1,w2,w3,wout,b1,b2,b3,bout)\n",
    "                    custotreino = cost(saidatreino,listabatchesytreino1)\n",
    "                gradients = tp.gradient(custotreino, trainable_vars)\n",
    "                optimizer.apply_gradients(zip(gradients, trainable_vars)) #Atualizaçao dos pesos e bias\n",
    "        tamanhobatch=deltabatch+l+1\n",
    "    \n",
    "    #Acuracia treino para cada epoca\n",
    "    saidatreino = saida(xtreino,w1,w2,w3,wout,b1,b2,b3,bout) #saida do modelo com os pesos e bias atualizados apos rodar todos os batches\n",
    "    custotreino = cost(saidatreino,ytreino)\n",
    "    verificacao=tf.equal(tf.argmax(saidatreino,1),tf.argmax(ytreino,1))\n",
    "    acuraciatreino=tf.math.reduce_mean(tf.cast(verificacao,tf.float32))\n",
    "    \n",
    "    #Saida do modelo e acuracia do teste para cada epoca\n",
    "    saidateste = saida(xteste,w1,w2,w3,wout,b1,b2,b3,bout)\n",
    "    verificacao=tf.equal(tf.argmax(saidateste,1),tf.argmax(yteste,1))\n",
    "    acuraciateste=tf.math.reduce_mean(tf.cast(verificacao,tf.float32))\n",
    "    \n",
    "    print(f'epoca{y}',f'custo:{custotreino}',f'acuracia treino:{acuraciatreino}',f'acuracia teste:{acuraciateste}')\n",
    "    #listacustotreino.append(custotreino) #grafico custo x epocas\n",
    "    #plt.plot(x, listacustotreino, '-g', label='Custo') #grafico custo x epocas\n",
    "    listaacurtreino.append(acuraciatreino) #grafico acuracia treino x epocas\n",
    "    #print('lista acuracia treino:',listaacurtreino)\n",
    "    plt.plot(x, listaacurtreino, '-g', label='Custo') #grafico acuracia treino x epocas\n",
    "    listaacurteste.append(acuraciateste) #grafico acuracia teste x epocas\n",
    "    plt.plot(x, listaacurteste, '-b', label='Custo') #grafico acuracia teste x epocas\n",
    "    \n",
    "tempofinal=time.time()\n",
    "tf.print('tempo em segundos', tempofinal - tempoinicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(yteste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listacaracteres={0:'a',1:'b',2:'c',3:'d',4:'e',5:'f',6:'g',7:'h',8:'i',9:'j',10:'k',11:'l',12:'m',13:'n',14:'o',15:'p',\n",
    "                 16:'q',17:'r',18:'s',19:'t',20:'u',21:'v',22:'w',23:'x',24:'y',25:'z',26:'0',27:'1',28:'2',29:'3',30:'4',\n",
    "                 31:'5',32:'6',33:'7',34:'8',35:'9'}\n",
    "print(listacaracteres[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "var=tf.argmax(saidateste[0],output_type=tf.int32)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18baafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(saidateste[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar os dados de teste x dados de saida do modelo, para ver em quais caracteres o modelo errou\n",
    "simbolos=string.ascii_lowercase + '0123456789'\n",
    "simbolos\n",
    "listacaracteres={0:'a',1:'b',2:'c',3:'d',4:'e',5:'f',6:'g',7:'h',8:'i',9:'j',10:'k',11:'l',12:'m',13:'n',14:'o',15:'p',\n",
    "                 16:'q',17:'r',18:'s',19:'t',20:'u',21:'v',22:'w',23:'x',24:'y',25:'z',26:'0',27:'1',28:'2',29:'3',30:'4',\n",
    "                 31:'5',32:'6',33:'7',34:'8',35:'9'}\n",
    "#for i in range(len(yteste)):\n",
    "for i in range(10):\n",
    "    print('#',i)\n",
    "    \n",
    "    #Gabarito\n",
    "    caractere=yteste[i] #Pega o caractere\n",
    "    #print('Vetor one hot encoding do Gabarito:',caractere)\n",
    "    posicaocaractere=np.argmax(caractere)\n",
    "    print('Simbolo caractere:',listacaracteres[posicaocaractere], '/ Posiçao caractere:',posicaocaractere)\n",
    "    \n",
    "    #Saida modelo\n",
    "    posicaosaida=np.argmax(saidateste[i])\n",
    "    print('Simbolo caractere:',listacaracteres[posicaosaida], '/ Saida Modelo:',posicaosaida)\n",
    "    \n",
    "    #Verificaçao da igualdade entre saida modelo e gabarito\n",
    "    verificacao=tf.equal(tf.argmax(saidateste[i]),tf.argmax(yteste[i]))\n",
    "    print('Erro(False) ou Acerto(True):',verificacao)\n",
    "    \n",
    "    #Exibição da imagem\n",
    "    cv2.imshow('Imagem caracter',xteste[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def conv1(entrada,w1,w2,w3,wout,b1,b2,b3,bout):\n",
    "    #Camada CNN1\n",
    "    conv1=conv2d(entrada,w1,b1) \n",
    "    pool1=maxpool(conv1,k=2)\n",
    "    #Camada CNN2\n",
    "    conv2=conv2d(pool1,w2,b2)\n",
    "    ##pool2=maxpool(conv2,k=2)\n",
    "    #Camada densa oculta\n",
    "    convcoluna=tf.reshape(conv2, shape=[-1,w3.get_shape().as_list()[0]])\n",
    "    densa1=tf.nn.relu(tf.add(tf.matmul(convcoluna, w3),b3))\n",
    "    ##dropoutdensa=tf.nn.dropout(densa1,0.2)\n",
    "    #Camda densa de saída\n",
    "    saida=tf.add(tf.matmul(densa1,wout),bout)\n",
    "    return conv1\n",
    "    #return saida\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolucao1=conv1(xteste,w1,w2,w3,wout,b1,b2,b3,bout)\n",
    "convolucao1 #32 feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a330ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convolucao1[0,:,:,0] #Selecionando apenas a primeira amostra e o primeiro feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolucao1[0,:,:,0]) #Selecionando apenas a primeira amostra e o primeiro feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolucao1[0,:,:,1])#Selecionando apenas a primeira amostra e o segundo feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolucao1[0,:,:,2]) #Selecionando apenas a primeira amostra e o terceiro feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b458e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolucao1[1,:,:,31]) #Selecionando apenas a segunda amostra e o trigesimo segundo feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def conv2(entrada,w1,w2,w3,wout,b1,b2,b3,bout):\n",
    "    #Camada CNN1\n",
    "    conv1=conv2d(entrada,w1,b1) \n",
    "    pool1=maxpool(conv1,k=2)\n",
    "    #Camada CNN2\n",
    "    conv2=conv2d(pool1,w2,b2)\n",
    "    ##pool2=maxpool(conv2,k=2)\n",
    "    #Camada densa oculta\n",
    "    convcoluna=tf.reshape(conv2, shape=[-1,w3.get_shape().as_list()[0]])\n",
    "    densa1=tf.nn.relu(tf.add(tf.matmul(convcoluna, w3),b3))\n",
    "    ##dropoutdensa=tf.nn.dropout(densa1,0.2)\n",
    "    #Camda densa de saída\n",
    "    saida=tf.add(tf.matmul(densa1,wout),bout)\n",
    "    return conv2\n",
    "    #return saida\n",
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolucao2=conv2(xteste,w1,w2,w3,wout,b1,b2,b3,bout)\n",
    "convolucao2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolucao2[1,:,:,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd41ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
